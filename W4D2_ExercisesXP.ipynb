{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJkF+ezlMM+r1UQsQ7AEL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhanna-naumenko/DI-Bootcamp/blob/main/W4D2_ExercisesXP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1**\n",
        "Identify whether each one is an example of structured or unstructured data.\n",
        "\n",
        "1. A company's financial reports stored in an Excel file - structured data as it is Excel file.\n",
        "2. Photographs uploaded to a social media platform - unstructured data, because it's photos.\n",
        "3. A collection of news articles on a website - unstructured data, because it's just collection\n",
        "4. Inventory data in a relational database - structured data, because inventory always connected to data which should be structured.\n",
        "5. Recorded interviews from a market research study - u can be either structured or unstructured data, depending on how it's stored and represented."
      ],
      "metadata": {
        "id": "W3x8bje4hZHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 2**\n",
        "For each of the following unstructured data sources, propose a method to convert it into structured data. Explain your reasoning.\n",
        "1. A series of blog posts about travel experiences. We can use Natural Language Processing (NLP) to extract relevant information such as locations visited, activities, accommodation details, ratings, reviews, and any other datas, because this could involve named entity recognition to identify locations and activities.\n",
        "2. Audio recordings of customer service calls. We can use speech-to-text transcription technology to convert the audio recordings into text transcripts. Once we transcribed it, apply text analysis techniques to identify common topics and named entity recognition to identify entities such as product names, service issues, customer names, etc. These extracted elements can then be structured into a database or spreadsheet format, with columns representing attributes like customer ID, call duration, issue discussed, resolution status, etc.\n",
        "3. Handwritten notes from a brainstorming session. We can use Optical Character Recognition (OCR) technology to convert the handwritten notes into machine-readable text. After this,  we can apply text analysis techniques to identify key concepts, ideas, action items, etc. This could involve parsing the text for keywords, categorizing ideas into topics or themes, and identifying relationships between different concepts. Once the information is extracted and analyzed, it can be structured into a structured document or spreadsheet, with columns representing attributes like idea ID, topic/category, description, owner, status, etc.\n",
        "4. A video tutorial on cooking. We can transcribe the audio content of the video tutorial using speech-to-text technology to obtain a textual transcript. Additionally, annotate the video to identify key steps, ingredients, cooking techniques, and time stamps corresponding to each part of the tutorial. Once transcribed and annotated, organize the information into a structured format such as a recipe database or cooking instructions spreadsheet, with columns representing attributes like recipe name, ingredient list, preparation steps, cooking time, difficulty level, etc."
      ],
      "metadata": {
        "id": "3VCIsdgGqUb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 3**\n",
        "You have access to various data sources, including transaction records, customer feedback comments, social media posts about your brand, and employee work schedules.\n",
        "Categorize each of these data sources as structured or unstructured.\n",
        "Suggest how you might use each type of data for improving the company's business operations\n",
        "\n",
        "1. Transaction records. It is structured data, because usually organized in a tabular format. By analyzing transaction data, companies can identify popular products, understand customer purchasing behavior, optimize pricing strategies, detect fraudulent transactions, and improve overall operational efficiency.\n",
        "2. Customer feedback comments. It is unstructured data, because usually it's typically free-form text. We can use this information to enhance product quality, refine marketing strategies, develop new products or features, and strengthen customer relationships.\n",
        "3. Social media posts about brand. It is unstructured data, because it can be indisserent format as text, images, videos, hashtags, mentions, and other multimedia content. Social media monitoring and analysis can help companies understand brand perception, monitor customer sentiment, track trends, engage with customers, and manage brand reputation. By analyzing social media posts, companies can identify influencers, respond to customer inquiries or complaints in real-time, launch targeted marketing campaigns, and gather market intelligence to inform business decisions.\n",
        "4. Employee work schedules. It is structured data, because usually organized in a tabular format. By analyzing employee work schedules, we can optimize staffing levels, ensure adequate coverage during peak hours, minimize overtime costs, identify scheduling conflicts or inefficiencies, and improve overall workforce productivity and morale."
      ],
      "metadata": {
        "id": "-rvrTQ8D-sfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 4**"
      ],
      "metadata": {
        "id": "oBrM-lHla661"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvK8bRo1a86b",
        "outputId": "57302b6d-3161-4452-8140-83630cb775e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-24.3.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-24.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "\n",
        "fake = Faker()\n",
        "data = []\n",
        "for _ in range(100):\n",
        "    user_id = np.random.randint(100,500)\n",
        "    user_name = fake.name().capitalize()\n",
        "    user_age = np.random.randint(20, 60)\n",
        "    user_address = fake.address()\n",
        "    user_email = fake.email()\n",
        "    user_income = np.random.randint(1500, 4000)\n",
        "    data.append([user_id, user_name, user_age, user_address, user_email, user_income])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Id', 'Name', 'Age', 'Address', 'Email', 'Income'])\n",
        "\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGdLUpCkbQk8",
        "outputId": "9eaec376-74a8-49ac-ffe3-ac9cd1fb4169"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Id              Name  Age  \\\n",
            "0  274      Natasha moon   25   \n",
            "1  179  Teresa maldonado   43   \n",
            "2  245     Amber barrera   24   \n",
            "3  415       Tammy black   49   \n",
            "4  204         Luis king   49   \n",
            "5  404   Jonathon taylor   20   \n",
            "6  375    Brooke leblanc   52   \n",
            "7  345       Julie jones   45   \n",
            "8  490      Travis davis   52   \n",
            "9  483        Alyssa cox   44   \n",
            "\n",
            "                                             Address  \\\n",
            "0  175 Bradley Stravenue Suite 825\\nPort Rickeysi...   \n",
            "1     588 Monica Pines Apt. 647\\nStacyside, VI 53137   \n",
            "2  08679 Martinez Ferry Suite 145\\nNew Joshuafurt...   \n",
            "3           8310 Hicks Radial\\nMichaelberg, RI 37931   \n",
            "4  4624 Loretta Station Apt. 071\\nYoungfort, NH 1...   \n",
            "5  26046 Ronnie Coves Suite 412\\nSouth Steven, KY...   \n",
            "6                   Unit 1908 Box 8254\\nDPO AE 76593   \n",
            "7  1365 James Trace Suite 986\\nStephanietown, VA ...   \n",
            "8       1865 Kyle Harbors\\nNorth Adamshire, IA 86002   \n",
            "9  5793 Raymond Bridge Suite 681\\nMckenziehaven, ...   \n",
            "\n",
            "                           Email  Income  \n",
            "0       dianevincent@example.org    3604  \n",
            "1             mbrown@example.net    3796  \n",
            "2   jacquelineporter@example.net    3532  \n",
            "3        dorismartin@example.net    2913  \n",
            "4         clarkricky@example.com    3243  \n",
            "5            zwillis@example.net    2832  \n",
            "6  christophermorgan@example.org    3794  \n",
            "7            brian32@example.com    1884  \n",
            "8         arodriguez@example.org    3424  \n",
            "9    marquezsamantha@example.com    1797  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 5**"
      ],
      "metadata": {
        "id": "kvKJZv_CdpmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "# Upload kaggle.json file (Run this cell and select your kaggle.json file through the file picker)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Make directory named kaggle and copy kaggle.json file there\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Change the permissions of the file\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "SB0Wsduudt2R",
        "outputId": "372e09f5-19b4-45e8-bb3c-850472cf575f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc903968-3c45-4920-baeb-81f93c58dea4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cc903968-3c45-4920-baeb-81f93c58dea4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d yaswanthgali/dog-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07EnTasrd1Eh",
        "outputId": "36c69e42-a750-41d6-fa4d-ea542049b4cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dog-images.zip"
      ],
      "metadata": {
        "id": "jMtxpARld9dt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "zra5xrQDe2Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEaoAegofBwC",
        "outputId": "ae108a55-f22e-4a7f-c958-05276ea176ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the file path\n",
        "image_path = '/content/dog_images/Images/n02085620-Chihuahua/n02085620_10074.jpg'\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(image_path):\n",
        "    print(\"File exists!\")\n",
        "else:\n",
        "    print(\"File not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpPYaYJimEOd",
        "outputId": "38f4b5c7-38d6-4250-c11c-f0caa91f922b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the path to save the dataset\n",
        "dataset_dir = '/content/images'\n",
        "\n",
        "# Define the directory containing the extracted images\n",
        "image_dir = os.path.join(dataset_dir, 'images')\n",
        "\n",
        "# Define the directory to save the augmented images\n",
        "augmented_dir = os.path.join(dataset_dir, 'augmented_images')\n",
        "\n",
        "# Create a directory to save the augmented images\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# Define the image data generator with specified transformations\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "# Generate augmented images and save them to the augmented directory\n",
        "batch_size = 32\n",
        "image_size = (150, 150)\n",
        "\n",
        "# Flow images from the image directory with augmentation\n",
        "data_flow = data_generator.flow_from_directory(\n",
        "    image_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    save_to_dir=augmented_dir,\n",
        "    save_prefix='aug_'\n",
        ")\n",
        "\n",
        "# Calculate the number of batches to generate\n",
        "num_batches = len(data_flow)\n",
        "\n",
        "# Generate and save augmented images\n",
        "for _ in range(num_batches):\n",
        "    next(data_flow)\n",
        "\n",
        "# Print completion message\n",
        "print(\"Augmented images generated and saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkhe2ljsjsx2",
        "outputId": "f6f1655e-4af1-4a8a-f79f-620340b48562"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20580 images belonging to 120 classes.\n",
            "Augmented images generated and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 6**\n",
        "\n",
        "To create traffic flow simulation we need to outline such steps. Firstly, to define city layout. We should check the roads, intersections, highways, residential areas, commercial districts, etc. Secondly, what road types do we have, is it highways, local streets, one-way streets, intersections, roundabouts, etc. Thirdly, wich types of vehicle a comonspread and are in the roads. Fourthly, the traffic signals and signs. And ofcourse such creteria as traffic paterns, wich include the volume of traffic, speed, and density for each time period; weather conditions, which can affect visibility, traffic signals (because I noticed that it is common spread that in Israel when it's raining the traffic signals just are crasy and stop working), road conditions, and vehicle behavior; emergency situations, such as accidents, road closures, construction zones, and vehicle breakdowns, and special events, like Purim))), concerts, sports games, parades, and festivals that may cause temporary changes in traffic patterns and congestion.\n",
        "To collect such data we can refer to Waze, Google maps or other such programms and apps. Or we can made our app and tried to implement it to collect data. Offcorse we should collect data from the simulation at regular intervals. We should collect such datas as number of vehicles on each road segment or at intersections, average speed of vehicles on different roads, measure of vehicle density on roads, rate of vehicles passing through specific points or segments, length of vehicle queues at intersections or traffic signals, time spent by vehicles at traffic signals or in congestion, information about accidents, breakdowns, or road closures.\n",
        "The simulated dataset can be used in various ways to improve traffic management and urban planning. We can optimiz traffic signal timing to reduce congestion and improve traffic flow. Identifying areas with high traffic volumes for infrastructure improvements such as road widening or adding new lanes. Evaluating the impact of new developments or infrastructure projects on traffic patterns and congestion. Developing predictive models for traffic forecasting and planning future transportation projects. Testing and validating intelligent transportation systems (ITS) and autonomous vehicle technologies. Enhancing emergency response planning by simulating scenarios and evaluating the effectiveness of evacuation routes and traffic management strategies."
      ],
      "metadata": {
        "id": "fi1CJ_9ukVNW"
      }
    }
  ]
}